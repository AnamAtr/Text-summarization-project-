{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnamAtr/Text-summarization-project-/blob/main/Text_Summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Installation & Environment Setup**"
      ],
      "metadata": {
        "id": "1BQqGM3Z_1kE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WEEYfeABim4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "046f0a78-795f-44d4-d8c9-96c3b8c08206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May 23 16:18:25 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P8              9W /   70W |       2MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1K9nrNTOjz_C"
      },
      "outputs": [],
      "source": [
        "pip install tranformers[sentencepiece] datasets sacrebleu rouge_score py7zr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXMfkJQOlHog"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade accelerate\n",
        "!pip install tranformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AA96tSxglOIp"
      },
      "outputs": [],
      "source": [
        "# Install the evaluate library\n",
        "!pip install evaluate\n",
        "\n",
        "# Remove the incorrect import of load_metric from datasets\n",
        "# from datasets import load_dataset, load_metric # <-- remove this part\n",
        "\n",
        "# Import load_metric from the correct library\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "# Import the evaluate library\n",
        "import evaluate\n",
        "\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "# Now you can load a specific metric like ROUGE using evaluate.load()\n",
        "# rouge = evaluate.load(\"rouge\") # Example of how to load a metric"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Require Libraries**"
      ],
      "metadata": {
        "id": "LjNGi5CQ_IzJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rt8nnwyBlz0J"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aMG6-yGQmXzQ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBwHByqumcs0"
      },
      "outputs": [],
      "source": [
        "model_ckpt=\"google/pegasus-cnn_dailymail\"\n",
        "tokenizer=AutoTokenizer.from_pretrained(model_ckpt)\n",
        "model_pegasus=AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Pre-trained Summarization model**"
      ],
      "metadata": {
        "id": "YU1hNorX_hAc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTskq8OpnRVy"
      },
      "outputs": [],
      "source": [
        "# Install and upgrade necessary libraries\n",
        "!pip install --upgrade datasets fsspec huggingface_hub\n",
        "\n",
        "# After upgrading, try loading the dataset again\n",
        "from datasets import load_dataset\n",
        "\n",
        "try:\n",
        "    ds = load_dataset(\"knkarthick/samsum\")\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "except ValueError as e:\n",
        "    print(f\"Failed to load dataset after upgrade: {e}\")\n",
        "    print(\"The issue might be with the dataset configuration itself or a persistent compatibility problem.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0te0lX_oAZv"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/entbappy/Branching-tutorial/blob/master/summarizer-data.zip\n",
        "!unzip summarizer-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZxezO9BqQNw"
      },
      "outputs": [],
      "source": [
        "!unzip summarizer-data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lIw_Y1o-qsMR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "3e112227-044a-4244-91ff-27dc1f25e242"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d1b26fc4-0ed2-48ef-88e0-a2281b103d90\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d1b26fc4-0ed2-48ef-88e0-a2281b103d90\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving summarizer-data (1).zip to summarizer-data (1).zip\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Input Text For Summarization**"
      ],
      "metadata": {
        "id": "RicQZaJkASY4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "KHg9mJbgswM7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83a73aa2-6f85-4b9e-f769-c7ff4f49f7e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ File unzipped successfully!\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_filename = list(uploaded.keys())[0]  # Automatically get the uploaded filename\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"unzipped_files\")  # Unzips into 'unzipped_files' folder\n",
        "\n",
        "print(\"✅ File unzipped successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "12ivo1W2tBR2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c7a61c0-ff0e-4447-ddb5-0bc3404f4965"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['samsum-test.csv',\n",
              " 'samsum-train.csv',\n",
              " 'samsum_dataset',\n",
              " 'samsum-validation.csv']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "os.listdir(\"unzipped_files\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18Pn9K2ft1Tw"
      },
      "outputs": [],
      "source": [
        "from datasets import load_from_disk\n",
        "import os\n",
        "\n",
        "# Assuming the dataset is located inside the 'unzipped_files' directory\n",
        "# Construct the absolute path to the dataset directory\n",
        "# Explicitly add the 'file://' protocol prefix for robustness\n",
        "dataset_path = \"file://\" + os.path.abspath('./unzipped_files/samsum_dataset')\n",
        "\n",
        "\n",
        "# Load the dataset using the absolute path\n",
        "try:\n",
        "    dataset_samsum = load_from_disk(dataset_path)\n",
        "    print(\"Dataset loaded successfully!\")\n",
        "except ValueError as e:\n",
        "    print(f\"Failed to load dataset: {e}\")\n",
        "    print(\"Please ensure the path is correct and the directory contains a valid dataset.\")\n",
        "    # Removed the line 'samsum_dataset' as it was a typo and caused a NameError\n",
        "    # If the dataset loading fails, dataset_samsum is not defined."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "th5FcjCSt7FN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63275715-df1c-45b3-d0c1-2b5510d927b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "split lengths:[14732, 819, 818]\n",
            "features:['id', 'dialogue', 'summary']\n",
            "\n",
            "Dialogue:\n",
            "Eric: MACHINE!\r\n",
            "Rob: That's so gr8!\r\n",
            "Eric: I know! And shows how Americans see Russian ;)\r\n",
            "Rob: And it's really funny!\r\n",
            "Eric: I know! I especially like the train part!\r\n",
            "Rob: Hahaha! No one talks to the machine like that!\r\n",
            "Eric: Is this his only stand-up?\r\n",
            "Rob: Idk. I'll check.\r\n",
            "Eric: Sure.\r\n",
            "Rob: Turns out no! There are some of his stand-ups on youtube.\r\n",
            "Eric: Gr8! I'll watch them now!\r\n",
            "Rob: Me too!\r\n",
            "Eric: MACHINE!\r\n",
            "Rob: MACHINE!\r\n",
            "Eric: TTYL?\r\n",
            "Rob: Sure :)\n",
            "\n",
            "Summary:\n",
            "Eric and Rob are going to watch a stand-up on youtube.\n"
          ]
        }
      ],
      "source": [
        "# Calculate the length of each split and store it in a list\n",
        "split_lengths=[len(dataset_samsum[split]) for split in dataset_samsum]\n",
        "print(f\"split lengths:{split_lengths}\")\n",
        "print(f\"features:{dataset_samsum['train'].column_names}\")\n",
        "print(\"\\nDialogue:\")\n",
        "print(dataset_samsum[\"test\"][1][\"dialogue\"])\n",
        "print(\"\\nSummary:\")\n",
        "print(dataset_samsum[\"test\"][1][\"summary\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "62Fv9hmvu3pY"
      },
      "outputs": [],
      "source": [
        "def convert_examples_to_features(example_batch):\n",
        "  input_encodings=tokenizer(example_batch['dialogue'],max_length=1024,truncation=True)\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    target_encodings=tokenizer(example_batch['summary'],max_length=128,truncation=True)\n",
        "  return{\n",
        "      'input_ids':input_encodings['input_ids'],\n",
        "      'attention_mask':input_encodings['attention_mask'],\n",
        "      'labels':target_encodings['input_ids']\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NnaRFfucwNJn"
      },
      "outputs": [],
      "source": [
        "# This cell initializes the tokenizer and should be run before the mapping cell\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Ensure model_ckpt is defined or re-define it\n",
        "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "\n",
        "# Ensure convert_examples_to_features is defined or re-define it\n",
        "def convert_examples_to_features(example_batch, tokenizer):\n",
        "  # The tokenizer is now passed as an argument\n",
        "  input_encodings=tokenizer(example_batch['dialogue'],max_length=1024,truncation=True)\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    target_encodings=tokenizer(example_batch['summary'],max_length=128,truncation=True)\n",
        "  return{\n",
        "      'input_ids':input_encodings['input_ids'],\n",
        "      'attention_mask':input_encodings['attention_mask'],\n",
        "      'labels':target_encodings['input_ids']\n",
        "  }\n",
        "\n",
        "# Pass the tokenizer to the map function using fn_kwargs\n",
        "# This assumes dataset_samsum is already loaded and available\n",
        "dataset_samsum_pt = dataset_samsum.map(\n",
        "    convert_examples_to_features,\n",
        "    batched=True,\n",
        "    fn_kwargs={\"tokenizer\": tokenizer} # Pass the tokenizer here\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zYL9Yi0wVcg"
      },
      "outputs": [],
      "source": [
        "dataset_samsum_pt[\"train\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Summary Analysis (Word Count & Reliability)**"
      ],
      "metadata": {
        "id": "kUP8A59aAuDP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "omaCjE0NxXWy"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "\n",
        "seq2seq_data_collator=DataCollatorForSeq2Seq(tokenizer,model=model_pegasus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "rS8P4IpnwqWy"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments,Trainer\n",
        "\n",
        "trainer_args = TrainingArguments(\n",
        "    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n",
        "    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
        "    weight_decay=0.01, logging_steps=10,\n",
        "    eval_strategy='steps', # Changed from evaluation_strategy to eval_strategy\n",
        "    eval_steps=500, save_steps=1e6,\n",
        "    gradient_accumulation_steps=16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3eqzxgiQ3by4"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "from transformers import TrainingArguments,Trainer\n",
        "\n",
        "# Initialize Weights & Biases\n",
        "wandb.init(project=\"pegasus-samsum-training\") # You can change the project name\n",
        "\n",
        "trainer_args = TrainingArguments(\n",
        "    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n",
        "    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
        "    weight_decay=0.01, logging_steps=10,\n",
        "    eval_strategy='steps', # Changed from evaluation_strategy to eval_strategy\n",
        "    eval_steps=500, save_steps=1e6,\n",
        "    gradient_accumulation_steps=16\n",
        ")\n",
        "\n",
        "trainer = Trainer(model=model_pegasus, args=trainer_args,\n",
        "                  tokenizer=tokenizer, data_collator=seq2seq_data_collator, # Corrected variable name\n",
        "                  train_dataset=dataset_samsum_pt[\"test\"],\n",
        "                  eval_dataset=dataset_samsum_pt[\"validation\"])\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Finish the Weights & Biases run\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1iiO-4dkCf1"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "from transformers import TrainingArguments,Trainer, AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# Initialize Weights & Biases\n",
        "wandb.init(project=\"pegasus-samsum-training\") # You can change the project name\n",
        "\n",
        "# Ensure device and model_ckpt are defined (assuming they are defined in previous cells)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
        "\n",
        "# Load the model and tokenizer (re-added these lines to ensure they are defined)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)\n",
        "\n",
        "trainer_args = TrainingArguments(\n",
        "    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n",
        "    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
        "    weight_decay=0.01, logging_steps=10,\n",
        "    eval_strategy='steps', # Changed from evaluation_strategy to eval_strategy\n",
        "    eval_steps=500, save_steps=1e6,\n",
        "    gradient_accumulation_steps=16\n",
        ")\n",
        "\n",
        "# Ensure seq2seq_data_collator and dataset_samsum_pt are defined in previous cells\n",
        "# These variables are likely defined in cells 'ipython-input-0-7eaa0621ad29' and\n",
        "# the cell loading/processing the dataset (e.g., 'ipython-input-9-7eaa0621ad29').\n",
        "# Make sure those cells are run before this one.\n",
        "trainer = Trainer(model=model_pegasus, args=trainer_args,\n",
        "                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
        "                  train_dataset=dataset_samsum_pt[\"test\"], # Using the test set for training as per the original code\n",
        "                  eval_dataset=dataset_samsum_pt[\"validation\"])\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Finish the Weights & Biasess run\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "wIR8paMP0Y0V"
      },
      "outputs": [],
      "source": [
        "def grenerate_batch_sized_chunks(list_of_elements,batch_size):\n",
        "  for i in range(0,len(list_of_elements),batch_size):\n",
        "    yield list_of_elements[i:i+batch_size]\n",
        "\n",
        "def Calculates_metric_on_test_ds(dataset,metric,model,tokenizer,batch_size=16,device=device,\n",
        "                                 column_text=\"article\",\n",
        "                                 column_summary=\"highlights\"):\n",
        "  article_batches=list(grenerate_batch_sized_chunks(dataset[column_text],batch_size))\n",
        "  target_batches=list(grenerate_batch_sized_chunks(dataset[column_summary],batch_size))\n",
        "  # Corrected indentation for the for loop and its content\n",
        "  for article_batch,target_batch in tqdm(\n",
        "      zip(article_batches,target_batches),total=len(article_batches)):\n",
        "      inputs=tokenizer(article_batch,max_length=1024,truncation=True,\n",
        "                        padding=\"max_length\",return_tensors=\"pt\")\n",
        "      summaries=model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
        "                               attention_mask=inputs[\"attention_mask\"].to(device),\n",
        "                               length_penalty=0.8,num_beams=8,max_length=128)\n",
        "      # Corrected indentation for the comment\n",
        "      # \" parameter for length penalty ensures that the model does not generate summaries that are too long.\"\n",
        "      decoded_summaries=[tokenizer.decode(s,skip_special_tokens=True,\n",
        "                                          clean_up_tokenization_spaces=True)\n",
        "                         for s in summaries]\n",
        "      decoded_summaries=[d.replace(\"\",\" \")for d in decoded_summaries]\n",
        "      metric.add_batch(predictions=decoded_summaries,references=target_batch)\n",
        "  # Corrected indentation for the return statement\n",
        "  score=metric.compute()\n",
        "  return score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Final Output & Insight\n"
      ],
      "metadata": {
        "id": "sq_DOnAWCJTo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4_fKAW82q1G"
      },
      "outputs": [],
      "source": [
        "!pip install rouge_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHVgC4lo2Xwh"
      },
      "outputs": [],
      "source": [
        "# Import the evaluate library (already imported earlier in the notebook, but good to be explicit here)\n",
        "import evaluate\n",
        "\n",
        "rouge_name=[\"rouge1\",\"rouge2\",\"rougeL\",\"rougeLsum\"]\n",
        "# Correct the function name from load_matric to evaluate.load\n",
        "rouge_metric = evaluate.load('rouge')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77G3Se2TEqVE"
      },
      "outputs": [],
      "source": [
        "# Correct the function name from Calculates_metric_on_test_ds to Calculates_metric_on_test_ds\n",
        "score = Calculates_metric_on_test_ds(\n",
        "    dataset_samsum['test'][0:10], rouge_metric, trainer.model, tokenizer, batch_size = 2, column_text = 'dialogue', column_summary= 'summary'\n",
        ")\n",
        "\n",
        "# Correct the function name in the second call as well\n",
        "# Removed the redundant second call to Calculates_metric_on_test_ds as it recalculates the score\n",
        "# score = Calculates_metric_on_test_ds(\n",
        "#     dataset_samsum['test'][0:10], rouge_metric, trainer.model, tokenizer, batch_size = 2, column_text = 'dialogue', column_summary= 'summary'\n",
        "# )\n",
        "\n",
        "# Modify the dictionary comprehension to directly access the float score\n",
        "rouge_dict = {}\n",
        "for rn in rouge_name:\n",
        "    # Directly access the float value for each ROUGE metric\n",
        "    # Check if the key exists to be safe, although based on the traceback it should\n",
        "    if rn in score:\n",
        "        rouge_dict[rn] = score[rn]\n",
        "\n",
        "pd.DataFrame(rouge_dict,index = [f'pegasus'])\n",
        "\n",
        "# Removed the redundant second creation of the DataFrame\n",
        "# rouge_dict=dict((rn,score[rn]['mid'].fmeasure)for rn in rouge_name)\n",
        "# pd.DataFrame(rouge_dict,index = [f'pegasus'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2DWLZqOZE3bO"
      },
      "outputs": [],
      "source": [
        "model_pegasus.save_pretrained(\"pegasus-samsum-model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "36ah_j3hGBNB"
      },
      "outputs": [],
      "source": [
        "tokenizer.save_pretrained(\"tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "MG_gcEwpGXca"
      },
      "outputs": [],
      "source": [
        "tokenizer=AutoTokenizer.from_pretrained(\"/content/tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "WiJdF9IiGonW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fedc049-ecff-4169-ef9b-5fd86007d293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n",
            "Your max_length is set to 128, but your input_length is only 122. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=61)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue:\n",
            "Hannah: Hey, do you have Betty's number?\n",
            "Amanda: Lemme check\n",
            "Hannah: <file_gif>\n",
            "Amanda: Sorry, can't find it.\n",
            "Amanda: Ask Larry\n",
            "Amanda: He called her last time we were at the park together\n",
            "Hannah: I don't know him well\n",
            "Hannah: <file_gif>\n",
            "Amanda: Don't be shy, he's very nice\n",
            "Hannah: If you say so..\n",
            "Hannah: I'd rather you texted him\n",
            "Amanda: Just text him 🙂\n",
            "Hannah: Urgh.. Alright\n",
            "Hannah: Bye\n",
            "Amanda: Bye bye\n",
            "\n",
            "Reference Summary:\n",
            "Hannah needs Betty's number but Amanda doesn't have it. She needs to contact Larry.\n",
            "\n",
            "Model Summary:\n",
            "Amanda: Ask Larry Amanda: He called her last time we were at the park together .<n>Hannah: I'd rather you texted him .<n>Amanda: Just text him .\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline, AutoTokenizer\n",
        "\n",
        "gen_kwargs={\"length_penalty\":0.8,\"num_beams\":8,\"max_length\":128}\n",
        "\n",
        "\n",
        "sample_text=dataset_samsum[\"test\"][0][\"dialogue\"]\n",
        "refrence=dataset_samsum[\"test\"][0][\"summary\"]\n",
        "\n",
        "# Import the pipeline function\n",
        "pipe=pipeline(\"summarization\",model=\"pegasus-samsum-model\",tokenizer=tokenizer)\n",
        "\n",
        "##\n",
        "print(\"Dialogue:\")\n",
        "print(sample_text)\n",
        "print(\"\\nReference Summary:\")\n",
        "print(refrence)\n",
        "print(\"\\nModel Summary:\")\n",
        "print(pipe(sample_text,**gen_kwargs)[0][\"summary_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example**"
      ],
      "metadata": {
        "id": "OzUm57A0CyDd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6uESGPoWHjng"
      },
      "outputs": [],
      "source": [
        "!pip install textstat\n",
        "\n",
        "from transformers import pipeline\n",
        "from textstat import flesch_reading_ease\n",
        "\n",
        "# Load summarization model (choose 'facebook/bart-large-cnn' or another)\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "# User input section\n",
        "print(\" Paste the text you want to summarize below:\")\n",
        "input_text = input(\"Paste Text Here:\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "QRvSOEiJtdkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1f4d491-df15-48a1-fa92-7d4505426472"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Paste the text you want to summarize below:\n",
            "Paste Text Here:\n",
            "Outside the funeral home, I heard a boy say that she had fallen off the back of her boyfriend’s motorcycle. Broken her neck. She never knew what hit her, he said. I was 13. The dead girl had been a junior in high school.  The line to see her snaked around the building. Boys with long hair, wearing ties they’d borrowed from their fathers, and girls with thick blue eyeshadow smoked cigarettes in the parking lot. Someone passed a bottle of Jack. There were no adults there, just very old kids.  She almost looked like she was sleeping, except that she was too still. There was a puffiness to her face that didn’t seem quite right. They had dressed her for the prom; the crinoline sleeves of her gown like poofs of pink cotton candy. Some kids prayed, but I couldn’t. I just stared at the roses in her corsage.\n",
            "\n",
            "✅ Summary:\n",
            " The dead girl had been a junior in high school. Outside the funeral home, I heard a boy say that she had fallen off the back of her boyfriend’s motorcycle. She never knew what hit her, he said.\n",
            "\n",
            "🔹 Summary Word Count: 38\n",
            "🔹 Readability Score: 87.11517543859652\n"
          ]
        }
      ],
      "source": [
        "# User input section\n",
        "print(\" Paste the text you want to summarize below:\")\n",
        "input_text = input(\"Paste Text Here:\\n\")\n",
        "\n",
        "\n",
        "if input_text.strip():\n",
        "\n",
        "    summary = summarizer(input_text, max_length=130, min_length=30, do_sample=False)[0]['summary_text']\n",
        "    readability = flesch_reading_ease(summary)\n",
        "    word_count = len(summary.split())\n",
        "\n",
        "    print(\"\\n✅ Summary:\\n\", summary)\n",
        "    print(\"\\n🔹 Summary Word Count:\", word_count)\n",
        "    print(\"🔹 Readability Score:\", readability)\n",
        "else:\n",
        "    print(\"⚠️ No input detected. Please paste a valid text.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNctwdZMa/aD6C2FiYF7LE/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}